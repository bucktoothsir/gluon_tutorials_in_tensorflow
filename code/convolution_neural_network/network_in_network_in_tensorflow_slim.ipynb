{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络中的网络\n",
    "Alexnet之后一个重要的工作是Network in Network（NiN），其提出的两个想法影响了后面的网络设计。\n",
    "\n",
    "首先一点是注意到卷积神经网络一般分成两块，一块主要由卷积层构成，另一块主要是全连接层。在Alexnet里我们看到如何把卷积层块和全连接层分别加深加宽从而得到深度网络。另外一个自然的想法是，我们可以串联数个卷积层块和全连接层块来构建深度网络。\n",
    "\n",
    "![image.png](http://zh.gluon.ai/_images/nin.svg)\n",
    "不过这里的一个难题是，卷积的输入输出是4D矩阵，然而全连接是2D。同时在卷积神经网络里我们提到如果把4D矩阵转成2D做全连接，这个会导致全连接层有过多的参数。NiN提出只对通道层做全连接并且像素之间共享权重来解决上述两个问题。就是说，我们使用kernel大小是$1×1$的卷积。\n",
    "\n",
    "下面代码定义一个这样的块，它由一个正常的卷积层接上两个kernel是$1×1$的卷积层构成。后面两个充当两个全连接层的角色。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "import pdb\n",
    "\n",
    "def mlpconv(input, channels, kernel_size, padding, scope, strides=1, max_pooling=True):\n",
    "    input = tf.pad(input, [[0,0],[padding,padding],[padding,padding],[0,0]])\n",
    "    conv1 = slim.conv2d(input, channels, [kernel_size, kernel_size], strides, scope=scope+'_conv1')\n",
    "    conv2 = slim.conv2d(conv1, channels, [1, 1], strides, scope=scope+'_conv2')\n",
    "    output = slim.conv2d(conv2, channels, [1, 1], strides, scope=scope+'_conv3')\n",
    "    if max_pooling:\n",
    "        output = slim.max_pool2d(output, [3, 3], 2, scope=scope+'_max_pool')\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"haha_max_pool/MaxPool:0\", shape=(32, 7, 7, 64), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = np.random.uniform(size=(32, 16, 16, 3)).astype(np.float32)\n",
    "print mlpconv(y, 64, 3, 0, 'haha')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NiN的卷积层的参数跟Alexnet类似，使用三组不同的设定\n",
    "\n",
    "- kernel: $11×11$, channels: 96\n",
    "- kernel: $5×5$, channels: 256\n",
    "- kernel: $3×3$, channels: 384\n",
    "\n",
    "除了使用了$1×1$卷积外，NiN在最后不是使用全连接，而是使用通道数为输出类别个数的mlpconv，外接一个平均池化层来将每个通道里的数值平均成一个标量。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ninnet(input, is_training):\n",
    "    with tf.variable_scope('nin') as sc:\n",
    "        mlpconv1 = mlpconv(input, 96, 11, 0, 'mlpconv1', strides=4)\n",
    "        mlpconv2 = mlpconv(mlpconv1, 256, 5, 2, 'mlpconv2')\n",
    "        mlpconv3 = mlpconv(mlpconv2, 384, 3, 1, 'mlpconv3')\n",
    "        dp = slim.dropout(mlpconv3, keep_prob=0.5, is_training=is_training)\n",
    "        # 目标类为10类\n",
    "        mlpconv4 = mlpconv(dp, 10, 3, 1, 'mlpconv4', max_pooling=False)\n",
    "        # 输入为 batch_size x 4 x 4 x 10, 通过AvgPool2D转成\n",
    "        # batch_size x 1 x 1 x 10。\n",
    "        avg_pool = slim.avg_pool2d(mlpconv4, [3, 3], scope='global_avg_pooling')\n",
    "        return slim.flatten(avg_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取数据并训练\n",
    "跟Alexnet类似，但使用了更大的学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/fashion_mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ../../data/fashion_mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../data/fashion_mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../data/fashion_mnist/t10k-labels-idx1-ubyte.gz\n",
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../../utils')\n",
    "import utils\n",
    "\n",
    "data_dir = '../../data/fashion_mnist'\n",
    "train_images, train_labels, test_images, test_labels = utils.load_data_fashion_mnist(data_dir, one_hot=True)\n",
    "print train_images.shape\n",
    "print test_images.shape\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import DataSet\n",
    "train_dataset = DataSet(train_images, train_labels, one_hot=True)\n",
    "test_dataset = DataSet(test_images, test_labels, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-3-a70e6f62bfb6>(5)ninnet()\n",
      "-> mlpconv1 = mlpconv(input, 96, 11, 0, 'mlpconv1', strides=4)\n",
      "(Pdb) n\n",
      "> <ipython-input-3-a70e6f62bfb6>(6)ninnet()\n",
      "-> mlpconv2 = mlpconv(mlpconv1, 256, 5, 2, 'mlpconv2')\n",
      "(Pdb) n\n",
      "> <ipython-input-3-a70e6f62bfb6>(7)ninnet()\n",
      "-> mlpconv3 = mlpconv(mlpconv2, 384, 3, 1, 'mlpconv3')\n",
      "(Pdb) n\n",
      "> <ipython-input-3-a70e6f62bfb6>(8)ninnet()\n",
      "-> dp = slim.dropout(mlpconv3, keep_prob=0.5, is_training=is_training)\n",
      "(Pdb) n\n",
      "> <ipython-input-3-a70e6f62bfb6>(10)ninnet()\n",
      "-> mlpconv4 = mlpconv(dp, 10, 3, 1, 'mlpconv4', max_pooling=False)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> <ipython-input-1-3f1192b28d80>(6)mlpconv()\n",
      "-> def mlpconv(input, channels, kernel_size, padding, scope, strides=1, max_pooling=True):\n",
      "(Pdb) n\n",
      "> <ipython-input-1-3f1192b28d80>(7)mlpconv()\n",
      "-> input = tf.pad(input, [[0,0],[padding,padding],[padding,padding],[0,0]])\n",
      "(Pdb) max_pooling\n",
      "False\n",
      "(Pdb) padding\n",
      "1\n",
      "(Pdb) n\n",
      "> <ipython-input-1-3f1192b28d80>(8)mlpconv()\n",
      "-> conv1 = slim.conv2d(input, channels, [kernel_size, kernel_size], strides, scope=scope+'_conv1')\n",
      "(Pdb) n\n",
      "> <ipython-input-1-3f1192b28d80>(9)mlpconv()\n",
      "-> conv2 = slim.conv2d(conv1, channels, [1, 1], strides, scope=scope+'_conv2')\n",
      "(Pdb) input\n",
      "<tf.Tensor 'nin/Pad_3:0' shape=(?, 3, 3, 384) dtype=float32>\n",
      "(Pdb) n\n",
      "> <ipython-input-1-3f1192b28d80>(10)mlpconv()\n",
      "-> output = slim.conv2d(conv2, channels, [1, 1], strides, scope=scope+'_conv3')\n",
      "(Pdb) n\n",
      "> <ipython-input-1-3f1192b28d80>(11)mlpconv()\n",
      "-> if max_pooling:\n",
      "(Pdb) n\n",
      "> <ipython-input-1-3f1192b28d80>(13)mlpconv()\n",
      "-> return output\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> <ipython-input-1-3f1192b28d80>(13)mlpconv()-><tf.Tens...=float32>\n",
      "-> return output\n",
      "(Pdb) n\n",
      "> <ipython-input-3-a70e6f62bfb6>(13)ninnet()\n",
      "-> avg_pool = slim.avg_pool2d(mlpconv4, [3, 3], scope='global_avg_pooling')\n",
      "(Pdb) nmlpconv4\n",
      "*** NameError: name 'nmlpconv4' is not defined\n",
      "(Pdb) mlpconv4\n",
      "<tf.Tensor 'nin/mlpconv4_conv3/Relu:0' shape=(?, 3, 3, 10) dtype=float32>\n",
      "(Pdb) n\n",
      "> <ipython-input-3-a70e6f62bfb6>(14)ninnet()\n",
      "-> return slim.flatten(avg_pool)\n",
      "(Pdb) avg_pool\n",
      "<tf.Tensor 'nin/global_avg_pooling/AvgPool:0' shape=(?, 1, 1, 10) dtype=float32>\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> <ipython-input-3-a70e6f62bfb6>(14)ninnet()-><tf.Tens...=float32>\n",
      "-> return slim.flatten(avg_pool)\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> <ipython-input-5-6a674b3949cf>(16)<module>()->None\n",
      "-> logits = ninnet(resize_input, is_training)\n",
      "(Pdb) n\n",
      "> /usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py(2885)run_code()\n",
      "-> sys.excepthook = old_excepthook\n",
      "(Pdb) n\n",
      "> /usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py(2901)run_code()\n",
      "-> outflag = 0\n",
      "(Pdb) n\n",
      "> /usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py(2902)run_code()\n",
      "-> return outflag\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py(2902)run_code()->0\n",
      "-> return outflag\n",
      "(Pdb) n\n",
      "> /usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py(2819)run_ast_nodes()\n",
      "-> for i, node in enumerate(to_run_exec):\n",
      "(Pdb) n\n",
      "> /usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py(2820)run_ast_nodes()\n",
      "-> mod = ast.Module([node])\n",
      "(Pdb) n\n",
      "> /usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py(2821)run_ast_nodes()\n",
      "-> code = compiler(mod, cell_name, \"exec\")\n",
      "(Pdb) n\n",
      "> /usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py(2822)run_ast_nodes()\n",
      "-> if self.run_code(code, result):\n",
      "(Pdb) n\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:718: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "> /usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py(2819)run_ast_nodes()\n",
      "-> for i, node in enumerate(to_run_exec):\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2818\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2819\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_run_exec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2820\u001b[0m                 \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2821\u001b[0m                 \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.14_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.14_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 1e1\n",
    "max_steps = 1000\n",
    "batch_size = 128\n",
    "height = width = 28\n",
    "num_channels = 1\n",
    "num_outputs = 10\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input_placeholder = tf.placeholder(tf.float32, [None, height, width, num_channels])\n",
    "resize_input = tf.image.resize_images(input_placeholder, [224, 224])\n",
    "gt_placeholder = tf.placeholder(tf.int64, [None, num_outputs])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "\n",
    "logits = ninnet(resize_input, is_training)\n",
    "loss = tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=gt_placeholder)\n",
    "acc = utils.accuracy(logits, gt_placeholder)\n",
    "\n",
    "test_images_reshape = np.reshape(np.squeeze(test_images), (test_images.shape[0], height, width, 1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train_op = optimizer.minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "test_acc = []\n",
    "\n",
    "for step in range(max_steps):\n",
    "    data, label = train_dataset.next_batch(batch_size)\n",
    "    data = np.reshape(data, (batch_size, height, width, num_channels))\n",
    "    feed_dict = {input_placeholder: data, gt_placeholder: label, is_training: True}\n",
    "    loss_, acc_, _ = sess.run([loss, acc, train_op], feed_dict=feed_dict)\n",
    "    print(\"Batch %d, Loss: %f, Train acc %f \" % (step, loss_, acc_))\n",
    "    if step % 100 == 0 and step != 0:\n",
    "        test_data, test_label = test_dataset.next_batch(100)\n",
    "        test_data = np.reshape(test_data, (100, height, width, num_channels))\n",
    "        test_loss_, test_acc_ = sess.run([loss, acc], feed_dict={input_placeholder: test_data, gt_placeholder: test_label, is_training: False})\n",
    "        print (\"Test Loss: %f, Test acc %f \" % (test_loss_, test_acc_))\n",
    "        \n",
    "for i in range(100):\n",
    "    test_data, test_label = test_dataset.next_batch(100)\n",
    "    test_data = np.reshape(test_data, (100, height, width, num_channels))\n",
    "    test_loss_, test_acc_ = sess.run([loss, acc], feed_dict={input_placeholder: test_data, gt_placeholder: test_label, is_training: False})\n",
    "    test_acc.append(test_acc_)\n",
    "print (\"Test Loss: %f, Test acc %f \" % (np.mean(test_loss_), np.mean(test_acc_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
